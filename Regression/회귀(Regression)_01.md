# 회귀(Regression)

---

- 데이터 값이 평균과 같은 일정한 값으로 돌아가려는 경향을

  이용한 통계학 기법

- 여러개의 독립변수와 한개의 종속변수 간의 상관관계를 모델링하는 기법

- 피처와 결정 값 데이터 기반에서 학습을 통해 **최적의 회귀계수**를 찾아내는 것

- 회귀 유형 구분

| 독립변수 개수       | 회귀 계수의 결합     |
| ------------------- | -------------------- |
| 1개 : 단일 회귀     | 선형 : 선형 회귀     |
| 여러 개 : 다중 회귀 | 비선형 : 비선형 회귀 |



## 선형회귀모델

- 일반 선형 회귀 : 예측값과 실제 값의 RSS를 최소화 할 수 있도록 회귀계수를 최적화, 규제적용 X
- 라쏘(Lasso) : L1규제 적용, 중요도가 낮은 피처의 회귀계수를 0으로 만듬 ->  피처선택기능
- 릿지(Ridge) : L2규제 적용, 상대적으로 큰 회귀계수의 영향력을 낮추기 위해 회귀계수값을 더 작게 만듬
- 엘라스틱넷(ElasticNet) : L1,L2 혼합, 피처가 많은 데이터셋에 적용
- 로지스틱 회귀(Logistic Regression) : 분류에 사용되는 선형회귀 모델



## 잔차

- 실제값과 회귀 모델의 차이에 따른 오류값을 **잔차**라고함

- 최적의 회귀모델 : 잔차 합이 최소가 되는 모델
- Error*Error = RSS
  - MAE(Mean Absolute Error) : 절대값을 취해서 더하는 방식
  - RSS(Redual Sum of Square) : 오류 값의 제곱을 구해서 더하는 방식





